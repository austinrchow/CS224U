{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'text_emotion.csv' does not exist: b'text_emotion.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-9775aa3d253c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"text_emotion.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentiment\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'empty'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# data = data[data.sentiment != 'neutral']\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentiment\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'boredom'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentiment\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'surprise'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/CS224U/CS224U-Final/.env/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    700\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/CS224U/CS224U-Final/.env/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/CS224U/CS224U-Final/.env/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/CS224U/CS224U-Final/.env/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1121\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1122\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1123\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1124\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/CS224U/CS224U-Final/.env/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1851\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'usecols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1852\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1853\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1854\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1855\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File b'text_emotion.csv' does not exist: b'text_emotion.csv'"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"text_emotion.csv\")\n",
    "data = data[data.sentiment != 'empty']\n",
    "# data = data[data.sentiment != 'neutral']\n",
    "data = data[data.sentiment != 'boredom']\n",
    "data = data[data.sentiment != 'surprise']\n",
    "# surprise = data[data.sentiment == 'surprise']\n",
    "# print(surprise.content)\n",
    "mapping = {'sadness': 0, 'worry':1, 'love': 2, 'hate': 3, 'anger':3,'enthusiasm': 4, 'fun': 4, 'happiness': 4, 'relief':4, 'neutral':5}\n",
    "sentiments = data[\"sentiment\"].replace(mapping).tolist()\n",
    "tweets = data[\"content\"].tolist()\n",
    "# for i in range(len(sentiments)):\n",
    "    \n",
    "# data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanedTweets = []\n",
    "for tweet in tweets:\n",
    "#     print(tweet)\n",
    "    tweet =  tweet.lower()\n",
    "    ats = re.findall(r\"@\\w+\", tweet)\n",
    "    for at in ats:\n",
    "        tweet = tweet.replace(at, \"\")\n",
    "    tweet = tweet.replace(\"&quot\",\" \")\n",
    "    tweet = tweet.replace('&amp;', 'and')\n",
    "    tweet = tweet.replace(\"...\",\" \")\n",
    "    tweet = tweet.replace(\"!\",\"\")\n",
    "    tweet = tweet.replace(\"?\",\"\")\n",
    "    tweet = tweet.replace(\".\",\"\")\n",
    "    tweet = tweet.replace(\"\\'\",\"\")\n",
    "    tweet = tweet.replace(\"&lt;\",\"\")\n",
    "    tweet = tweet.replace(\"&gt;\",\"\")\n",
    "    tweet = tweet.strip()\n",
    "    tweet = re.sub(' +',' ',tweet)\n",
    "    tweet = ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \" \", tweet).split())\n",
    "    cleanedTweets.append(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = []\n",
    "for i in range(len(sentiments)):\n",
    "    combined.append([cleanedTweets[i], sentiments[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['layin n bed with a headache ughhhh waitin on your call', 0], ['funeral ceremony gloomy friday', 0], ['wants to hang out with friends soon', 4], ['we want to trade with someone who has houston tickets but no one will', 5], ['re pinging why didnt you go to prom bc my bf didnt like my friends', 1], ['i should be sleep but im not thinking about an old friend who i want but hes married now damn and he wants me scandalous', 0], ['hmmm is down', 1], ['charlene my love i miss you', 0], ['im sorry at least its friday', 0], ['cant fall asleep', 5]]\n"
     ]
    }
   ],
   "source": [
    "print(combined[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('cleaneddata6.csv', 'w') as myfile:\n",
    "    wr = csv.writer(myfile)\n",
    "    wr.writerows(r+[\"\"] for r in combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2216\n",
      "8602\n",
      "                                                 content  sentiment\n",
      "1996   anyways so my teacher was worried that i was g...          2\n",
      "1997                                     promise worried          2\n",
      "1998   someone go get back to his house he s been wan...          2\n",
      "1999   jaycee thinks australians speak australian not...          2\n",
      "2000   again i wonder what would make bb s trainer sc...          2\n",
      "2001     it still says pending will i be in by 5 worried          2\n",
      "2002   its a recurring theme of silly errors dropped ...          2\n",
      "2003   thanks for this it s really worried me i ve ch...          2\n",
      "2004         carnall where are you me and are so worried          2\n",
      "2005      can someone please tell me if is alive worried          2\n",
      "2006   my dog loves so much he actually ate it rip ca...          2\n",
      "2007   you responded quite a bit too late and i gave ...          2\n",
      "2008                why attendance so low worried tensed          2\n",
      "2009   my app isn t working right all the history is ...          2\n",
      "2010   just gave a 2 minute long speech for oratory c...          2\n",
      "2011   what is distracting you worried destiny goals ...          2\n",
      "2012   lord do you not care that my sister has left m...          2\n",
      "2013   are you always sceptical worried worries worry...          2\n",
      "2014                                    are u ok worried          2\n",
      "2015   she has been by my side all night she knows i ...          2\n",
      "2016   worried about higher studies selection get exp...          2\n",
      "2017   what for u is for u through christ jesus why a...          2\n",
      "2018    today is the tomorrow we worried about yesterday          2\n",
      "2019   are condomslubssex pills and sex toys also aff...          2\n",
      "2020   are condomslubssex pills and sex toys also aff...          2\n",
      "2021    today is the tomorrow we worried about yesterday          2\n",
      "2022   performance iike these r not acceptable at all...          2\n",
      "2023                         did you get home ok worried          2\n",
      "2024   tgif hello my dear friends i know you are worr...          2\n",
      "2025   i wish my lyft feedback could be anonymous my ...          2\n",
      "...                                                  ...        ...\n",
      "45117  i changed my mind dammit a tsar can change his...          2\n",
      "45120  searching my home for a few things to cook the...          2\n",
      "45123  happy mothers day ugh sick school tomorrow wat...          2\n",
      "45132  watching click they are talkin about twitter a...          2\n",
      "45134  oh mann das ist super lustig du armer macs age...          2\n",
      "45135  home from whitney s no sleep church in a bit d...          2\n",
      "45149  actually i also thought mother s day was may 3...          2\n",
      "45154  evening yorkshire s warm but overcast how s nz...          2\n",
      "45157  doing the andy dance the one on fonzie gomez s...          2\n",
      "45173  whats your name adelaide marie how old r u 14 ...          2\n",
      "45176                            fred6 shivers with fear          2\n",
      "45180                           thanks but what happened          2\n",
      "45181  man i hate church has to be done though i like...          2\n",
      "45184  thinking about recent job opportunities and ho...          2\n",
      "45190             heaps keen for next weekend mummy lt 3          2\n",
      "45192  indeed we live a life on the edge of things an...          2\n",
      "45194  it s never too late they just need to buck the...          2\n",
      "45202  have a great day if the rain keeps up i may go...          2\n",
      "45203  one could use garageband though it s probably ...          2\n",
      "45204  chillingoutnow just testing how to work twitte...          2\n",
      "45210  it takes nearly 2 days to figure out what caus...          2\n",
      "45211  luke m here thanks ps chris ur husband is pret...          2\n",
      "45217  hmmm sisch amp sound design so when you say so...          2\n",
      "45244  tomorrow is going to be sooo awkward amp embar...          2\n",
      "45246  hey negative on the primatech this handle s be...          2\n",
      "45247              haha and twitter hard though isn t it          2\n",
      "45249  sure but be careful also of making statements ...          2\n",
      "45264                   how do you sleep jesse mccartney          2\n",
      "45273                         is heading off to the fair          2\n",
      "45286  bloody feds they lost last statement and r hou...          2\n",
      "\n",
      "[15938 rows x 2 columns]\n",
      "32594\n"
     ]
    }
   ],
   "source": [
    "data2 = pd.read_csv(\"data.csv\")\n",
    "data2.head()\n",
    "four = data2[data2.sentiment == 4]\n",
    "three = data2[data2.sentiment == 3]\n",
    "two = data2[data2.sentiment == 2]\n",
    "one = data2[data2.sentiment == 1]\n",
    "\n",
    "print(four.size)\n",
    "print(three.size)\n",
    "print(two)\n",
    "print(one.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
